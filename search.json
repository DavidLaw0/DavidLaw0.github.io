[
  {
    "objectID": "Full_Stack/project5.html",
    "href": "Full_Stack/project5.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Full Stack",
      "Project 5"
    ]
  },
  {
    "objectID": "Full_Stack/project4.html",
    "href": "Full_Stack/project4.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Full Stack",
      "Project 4"
    ]
  },
  {
    "objectID": "Full_Stack/project3.html",
    "href": "Full_Stack/project3.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Full Stack",
      "Project 3"
    ]
  },
  {
    "objectID": "Cleansing_Exploration/project5.html",
    "href": "Cleansing_Exploration/project5.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top"
  },
  {
    "objectID": "Cleansing_Exploration/project4.html",
    "href": "Cleansing_Exploration/project4.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top"
  },
  {
    "objectID": "Cleansing_Exploration/project3.html",
    "href": "Cleansing_Exploration/project3.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top"
  },
  {
    "objectID": "cleansing.html",
    "href": "cleansing.html",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics",
    "crumbs": [
      "Data Cleansing"
    ]
  },
  {
    "objectID": "cleansing.html#title-2-header",
    "href": "cleansing.html#title-2-header",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics",
    "crumbs": [
      "Data Cleansing"
    ]
  },
  {
    "objectID": "Cleansing_Projects/project1.html",
    "href": "Cleansing_Projects/project1.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Data Cleansing",
      "Project 1"
    ]
  },
  {
    "objectID": "Cleansing_Projects/project2.html",
    "href": "Cleansing_Projects/project2.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Data Cleansing",
      "Project 2"
    ]
  },
  {
    "objectID": "Story_Telling/project5.html",
    "href": "Story_Telling/project5.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Story Telling",
      "Project 5"
    ]
  },
  {
    "objectID": "Story_Telling/project4.html",
    "href": "Story_Telling/project4.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Story Telling",
      "Project 4"
    ]
  },
  {
    "objectID": "Story_Telling/project3.html",
    "href": "Story_Telling/project3.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Story Telling",
      "Project 3"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "index.html#title-2-header",
    "href": "index.html#title-2-header",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "Machine_Learning/project1.html",
    "href": "Machine_Learning/project1.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Machine Learning",
      "Project 1"
    ]
  },
  {
    "objectID": "Machine_Learning/project2.html",
    "href": "Machine_Learning/project2.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Machine Learning",
      "Project 2"
    ]
  },
  {
    "objectID": "ml.html",
    "href": "ml.html",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics",
    "crumbs": [
      "Machine Learning"
    ]
  },
  {
    "objectID": "ml.html#title-2-header",
    "href": "ml.html#title-2-header",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics",
    "crumbs": [
      "Machine Learning"
    ]
  },
  {
    "objectID": "story_telling.html",
    "href": "story_telling.html",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics",
    "crumbs": [
      "Story Telling"
    ]
  },
  {
    "objectID": "story_telling.html#title-2-header",
    "href": "story_telling.html#title-2-header",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics",
    "crumbs": [
      "Story Telling"
    ]
  },
  {
    "objectID": "Competition/project5.html",
    "href": "Competition/project5.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Competition",
      "Project 5"
    ]
  },
  {
    "objectID": "Competition/project4.html",
    "href": "Competition/project4.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Competition",
      "Project 4"
    ]
  },
  {
    "objectID": "Competition/project3.html",
    "href": "Competition/project3.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Competition",
      "Project 3"
    ]
  },
  {
    "objectID": "Competition/project2.html",
    "href": "Competition/project2.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Competition",
      "Project 2"
    ]
  },
  {
    "objectID": "Competition/project1.html",
    "href": "Competition/project1.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Competition",
      "Project 1"
    ]
  },
  {
    "objectID": "competition.html",
    "href": "competition.html",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics",
    "crumbs": [
      "Competition"
    ]
  },
  {
    "objectID": "competition.html#title-2-header",
    "href": "competition.html#title-2-header",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics",
    "crumbs": [
      "Competition"
    ]
  },
  {
    "objectID": "exploration.html",
    "href": "exploration.html",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics",
    "crumbs": [
      "Data Exploration"
    ]
  },
  {
    "objectID": "exploration.html#title-2-header",
    "href": "exploration.html#title-2-header",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics",
    "crumbs": [
      "Data Exploration"
    ]
  },
  {
    "objectID": "Machine_Learning/project3.html",
    "href": "Machine_Learning/project3.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Machine Learning",
      "Project 3"
    ]
  },
  {
    "objectID": "Machine_Learning/project4.html",
    "href": "Machine_Learning/project4.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Machine Learning",
      "Project 4"
    ]
  },
  {
    "objectID": "Machine_Learning/project5.html",
    "href": "Machine_Learning/project5.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Machine Learning",
      "Project 5"
    ]
  },
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "David Lawrence’s cv",
    "section": "",
    "text": "Phone: (309)-533-3431 \\ Email: drl.lawrence2@gmail.com \\ LinkedIn: https://www.linkedin.com/in/davidlawrence001/"
  },
  {
    "objectID": "resume.html#legal-intern",
    "href": "resume.html#legal-intern",
    "title": "David Lawrence’s cv",
    "section": "Legal Intern \\",
    "text": "Legal Intern \\\nHuhem Law Firm PLLC — Dallas, Texas \\ July 2025 – September 2025\n\nIdentified a procedural gap during trial preparation by consulting opposing counsel post-hearing and recommended a documentation protocol, saving clients hundreds of dollars per case\nDrafted and filed legal documents including eviction petitions, civil litigation petitions, demand letters, and legal memos\nRepresented firm’s clients in court as an agent, winning more than 90% of cases"
  },
  {
    "objectID": "resume.html#volunteer",
    "href": "resume.html#volunteer",
    "title": "David Lawrence’s cv",
    "section": "Volunteer \\",
    "text": "Volunteer \\\nChurch of Jesus Christ of Latter-Day Saints — Abidjan, Côte d’Ivoire \\ November 2021 – November 2023\n\nServed as a full-time volunteer focusing on planning, goal setting, leadership, and creating service opportunities\nGained conversational and written fluency in French within six months by working daily with native speakers\nTrained and supervised more than 20 volunteers by teaching French, cultural norms, and effective teaching techniques"
  },
  {
    "objectID": "resume.html#front-desk-receptionist",
    "href": "resume.html#front-desk-receptionist",
    "title": "David Lawrence’s cv",
    "section": "Front Desk Receptionist \\",
    "text": "Front Desk Receptionist \\\nDoubleTree by Hilton — Bloomington, Illinois \\ April 2021 – October 2021\n\nSolved problems under pressure, ensuring accurate payments and improving workflow, preventing major financial losses\nImproved efficiency by optimizing guest records and proactively addressing special requests, saving an average of one hour during rush periods\nProvided exceptional service by fulfilling custom client requests beyond standard job duties\nElevated workplace appearance by consistently wearing a suit, inspiring coworkers to follow"
  },
  {
    "objectID": "Story_Telling/project2.html",
    "href": "Story_Telling/project2.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Story Telling",
      "Project 2"
    ]
  },
  {
    "objectID": "Story_Telling/project1.html",
    "href": "Story_Telling/project1.html",
    "title": "NYC Bikes",
    "section": "",
    "text": "Everyday there are hundreds of accidents in New York City. The large population means that the roads are crowded and driving can be dangerous. In order to avoid the traffic many residents choose to use bikes as a means of transport. Although this method might save time and provide good exercise it also comes with an increase in risk. Bikers* are more exposed than other commuters and must exercise more precaution. An effort to understand the cause, location, and frequency of accidents might lead to real world changes that could save lives.\n*This analysis only shows the Bicycle accidents not motorcycle.\n\n\nIn this analysis I use data collected from Kaggle. Namely, the Central Park NYC Weather Information data set that has weather information from the central park weather station from the years 2000-2022. As well as the Motor Vehicle Collisions - Crashes data set that has all police reported crashes in NYC. To keep the analysis relevant I decided to filter the data to include only years 2021 and 2022 (the two most recent years from the weather data set). I then filtered the motor vehicle collisions in two ways.\n\nBy longitude and latitude to focus on Manhattan surrounding central park, so the weather information might be accurate to the crash incidents.\nI limited the crashes to only those that included a bicycle since that is our target group.\n\n\n\nShow the code\nny1 &lt;- ny %&gt;%\n  mutate(`CRASH DATE` = mdy(`CRASH DATE`))\n\n\nny_clean &lt;- ny1 %&gt;%\n  filter(!is.na(LATITUDE), !is.na(LONGITUDE),\n         LATITUDE  &gt; 40.708073, LATITUDE  &lt; 40.833170,\n         LONGITUDE &gt; -74.013195, LONGITUDE &lt; -73.930574)\n\n\nny_2022 &lt;- ny_clean %&gt;%\n  filter(year(`CRASH DATE`) &gt;= 2021 & year(`CRASH DATE`) &lt;= 2022) %&gt;%\n  rename(DATE = `CRASH DATE`)\n\n\nwet_clean &lt;- wet %&gt;%\n  filter(year(DATE) &gt;= 2021 & year(DATE) &lt;= 2022,\n         STATION == \"USW00094728\") %&gt;%\n  select(DATE, PRCP, TMAX, TMIN, SNOW)\n\n# Final dataset with weather\nny8 &lt;- ny_2022 %&gt;%\n  left_join(wet_clean, by = \"DATE\")\n\n\nbike_crashes &lt;- ny8 %&gt;%\n  filter(`NUMBER OF CYCLIST INJURED` &gt; 0 | `NUMBER OF CYCLIST KILLED` &gt; 0 |\n         str_detect(tolower(`VEHICLE TYPE CODE 1`), \"bike|bicycle\") |\n         str_detect(tolower(`VEHICLE TYPE CODE 2`), \"bike|bicycle\") |\n         str_detect(tolower(`VEHICLE TYPE CODE 3`), \"bike|bicycle\") |\n         str_detect(tolower(`VEHICLE TYPE CODE 4`), \"bike|bicycle\") |\n         str_detect(tolower(`VEHICLE TYPE CODE 5`), \"bike|bicycle\")) %&gt;%\n  mutate(\n    year= year(DATE),\n    month = month(DATE, label = TRUE),\n    day_of_week = wday(DATE, label = TRUE, abbr = FALSE),\n    is_rainy= if_else(PRCP &gt; .05, \"Rain\", \"Dry\"),    # &gt;0.01 inches = rainy day\n    severity = case_when(\n      `NUMBER OF CYCLIST KILLED` &gt; 0 ~ \"Fatal\",\n      `NUMBER OF CYCLIST INJURED` &gt; 0 ~ \"Injury\",\n      TRUE ~ \"Property Damage Only\"\n    ),top_factor = `CONTRIBUTING FACTOR VEHICLE 1`,\n    top_factor = if_else(is.na(top_factor) | top_factor %in% c(\"\", \"Unspecified\"),\n                         \"Other/Unspecified\", top_factor))\n\n\n\ncat(\"Total bike-involved crashes 2021-2022:\", nrow(bike_crashes), \"\\n\")\n\n\nTotal bike-involved crashes 2021-2022: 4685 \n\n\n\n\n\nThe data wrangling process was made relatively simple by Kaggle’s high standard of clean data. Most of the adjustments were simple filters to target the data I needed, mutates to add categorical bins, as well as a join to combine the data sets. As you can see this left us with 4,685 rows of data to work with.\nThere were a few choices that I had to make while defining a “rainy” day or the “severity” of the accident. I choose classify any precipitation &gt; 0.05 mm/hr as a rainy day. (I will examine the effects of changing this number later in the analysis). Although this is in reality very little rain it is still enough to make the pavement wet and have an effect on the accident rates. In my second graph below I examine the precipitation vs bike crashes and find very little relevance and so this decision seems to be inconsequential. Severity was determined as follows, if there were any fatalities than the accident was considered “Fatal”, if there was an injury than it was grouped as “Injury” and if neither of these, the accident was classified as “Property Damage Only” under the assumption that some damage occurred to the bike or vehicle.\n\n\n\nThe map below serves as the focal point of this project, and it servers a few function.\n\nIt shows the density of accidents such that it is easy to determine problematic areas.\nThe marker of each accident is color coded for the type or weather, or whether or not the accident was fatal. Since a Fatal accident is viewed with more gravity I decided this would trump the weather color coding, however by clicking on a marker you are able to see weather information for that day.\nThe interactive map shows the reason for each accident. This could be useful if you are examining a particular area and trying to determine if there is a correlation between that area and the contributing factor. (For example there might be more “distracted driver” factors around Times Square.)\n\nUser note: In order to find the most dense crash area simply click on the cluster with the largest number and continue to do so until you reach the street level were you can click on each marker to get more information.\n\n\nShow the code\npal &lt;- colorFactor(\n  palette = c(\"Dry\" = \"orange\", \"Rain\" = \"red\", \"Fatal\" = \"dodgerblue2\"),\n    domain = c(\"Dry\", \"Rain\", \"Fatal\")) # after like 20mins of playing with it I just accepted it's weird\n\nleaflet(data = bike_crashes) %&gt;%\n\n  addProviderTiles(providers$CartoDB.Positron) %&gt;%\n  \n    addHeatmap(\n    lng = ~LONGITUDE, lat = ~LATITUDE,\n    blur = 25, max = 0.1, radius = 15) %&gt;%\n  \n  addCircleMarkers(\n    lng = ~LONGITUDE, lat = ~LATITUDE,\n    radius = 10,\n    color = ~pal(ifelse(`NUMBER OF CYCLIST KILLED` &gt; 0, \"Fatal\", is_rainy)),\n    fillOpacity = 1,\n    \n    popup = ~paste(\n      \"&lt;b&gt;Date:&lt;/b&gt;\", DATE, \"&lt;br&gt;\",\n      \"&lt;b&gt;Weather:&lt;/b&gt;\", is_rainy, \"(\", round(PRCP,2), \" mm/hr)\", \"&lt;br&gt;\",\n      \"&lt;b&gt;Injured:&lt;/b&gt;\", `NUMBER OF CYCLIST INJURED`,\n      \"&lt;b&gt;Killed:&lt;/b&gt;\", `NUMBER OF CYCLIST KILLED`, \"&lt;br&gt;\",\n      \"&lt;b&gt;Main factor:&lt;/b&gt;\", top_factor),\n    \n    clusterOptions = markerClusterOptions() # Had some help making the popups and clusters\n  ) %&gt;%\n  addLegend(\"bottomright\",\n            pal = pal, values = c(\"Dry\", \"Rain\", \"Fatal\"),\n            title = \"Weather / Severity\")\n\n\n\n\n\n\n\n\n\nThe graph below shows the correlation between rainfall (precipitation) and bike crashes. The purpose was to see if there was in fact a correlation between the amount of rain and the number of crashes. The answer seems to be no. My theory is that the more that it rains, the less cyclists there are on the road. To determine whether there is a higher proportion of crashes per rider one would have to know how many cyclists are riding at that moment and out of that total number how many got into an accident. Unfortunately I don’t think that data is feasible to collect. Using the slider you can see that often a peak in precipitation is met with a dip in crashes, meaning a weak correlation, while there some spikes that align the majority miss each other.\n\n\nShow the code\ndaily &lt;- bike_crashes %&gt;%\n  count(DATE, is_rainy) %&gt;%\n  complete(DATE = seq(min(DATE), max(DATE), by = \"day\"), fill = list(n = 0)) %&gt;%\n  left_join(select(wet_clean, DATE, PRCP), by = \"DATE\") %&gt;%\n  replace_na(list(PRCP = 0))\n\nts_data &lt;- xts(daily[, c(\"n\", \"PRCP\")], order.by = daily$DATE)\n\ndygraph(ts_data, main = \"Daily Bicycle Crashes vs Precipitation (2021-2022)\") %&gt;%\n  \n  dySeries(\"n\", label = \"Bike Crashes\", color = \"red\") %&gt;%\n  \n  dySeries(\"PRCP\", label = \"Precipitation (mm)\", axis = \"y2\", color = \"royalblue\") %&gt;%\n  \n  dyAxis(\"y\", label = \"Number of Crashes\") %&gt;%\n  \n  dyAxis(\"y2\", label = \"Precipitation (mm)\", independentTicks = TRUE) %&gt;%\n  \n  dyRangeSelector() %&gt;%\n  \n  dyHighlight(highlightSeriesOpts = list(strokeWidth = 3)) %&gt;%\n  \n  dyOptions(fillGraph = TRUE) \n\n\n\n\n\n\nI made a simplified graph to show the average number of bike crashes on each day of the week split between rainy and dry days. It appears the fewest number of people are traveling Sunday, which makes sense and there is a gradual increase throughout the week with a peak on Thursday and Friday. Notice that there are fewer crashes on rainy days each day of the week, except for Tuesday by a small margin once again confirming my theory of fewer bike commuters on those wet days.\n\n\nShow the code\ndaily_rates &lt;- bike_crashes %&gt;%\n  count(DATE, day_of_week, is_rainy) %&gt;%\n  group_by(day_of_week, is_rainy) %&gt;%\n  summarise(avg_crashes = mean(n)) %&gt;%\n  ungroup()\n\n\nggplot(daily_rates, aes(x = day_of_week, y = avg_crashes, fill = is_rainy)) +\n  \n\n  geom_col(position = \"dodge\", color = \"black\", size = 0.3) +\n  \n  scale_fill_manual(values = c(\"Dry\" = \"orange\", \"Rain\" = \"dodgerblue2\"), name = \"\") +\n  \n  labs(title = \"Bike Crashes, Rainy vs Dry Days\",\n       subtitle = \"Average daily crashes (2021-2022)\",\n       x = \"\",\n       y = \"Average Number of Bike Crashes per Day\") +\n  \n  theme_minimal() +\n  \n  theme(legend.position = \"top\")\n\n\n\n\n\n\n\n\n\nFor the sake of trying to uncover trends I’m going to change the standard for what is considered a rainy day by tripling the mm/hr precipitation rate from .05mm to 1.5mm/hr. The goal is to show the effect that more rain has on road conditions. If there is little to no change than we can conclude that rain plays little affect in the number of crashes. However if there is an effect we can assume that there is in fact a correlation\n\n\nShow the code\nbike_crashes2 &lt;- bike_crashes %&gt;% \n  mutate(is_rainy= if_else(PRCP &gt; 1.5, \"Rain\", \"Dry\"))\n\n\ndaily_rates2 &lt;- bike_crashes2 %&gt;%\n  count(DATE, day_of_week, is_rainy) %&gt;%\n  group_by(day_of_week, is_rainy) %&gt;%\n  summarise(avg_crashes = mean(n)) %&gt;%\n  ungroup()\n\nggplot(daily_rates2, aes(x = day_of_week, y = avg_crashes, fill = is_rainy)) +\n  \n\n  geom_col(position = \"dodge\", color = \"black\", size = 0.3) +\n  \n  scale_fill_manual(values = c(\"Dry\" = \"orange\", \"Rain\" = \"dodgerblue2\"), name = \"\") +\n  \n  labs(title = \"Bike Crashes, Rainy vs Dry Days\",\n       subtitle = \"Average daily crashes (2021-2022)\",\n       x = \"\",\n       y = \"Average Number of Bike Crashes per Day\") +\n  \n  theme_minimal() +\n  \n  theme(legend.position = \"top\")\n\n\n\n\n\n\n\n\n\nTaking a look at the graph we see that there was a change in the average number of accidents a day for most days it appears that Tuesday sees the greatest differential towards rainy day crashes and Saturday for dry day. Notably Saturday and Sunday have the biggest difference in favor of dry days most likely do the elastic need to travel those days.\n\n\n\nFinally the last chart examines the cause of accident depending on the weather that day. The two bars are almost identical such that little can be said for the affect of the rain on the reason for the accident. Once again lets change the classification for rainy day and see the effect.\n\n\nShow the code\ntop_factors &lt;- bike_crashes %&gt;%\n  count(is_rainy, top_factor) %&gt;%\n  group_by(is_rainy) %&gt;%\n  slice_max(n, n = 10) %&gt;%\n  ungroup() %&gt;%\n  mutate(top_factor = fct_reorder(top_factor, n, sum))\n\n\n\nggplot(top_factors, aes(x = is_rainy, y = n, fill = top_factor)) +\n  \n  geom_col(position = \"fill\", color = \"white\", size = 0.3) +\n  \n  scale_y_continuous(labels = percent) +\n  \n  scale_fill_viridis_d(option = \"turbo\") + #took me forever to find a good color scheme lol\n  \n  labs(title = \"Contributing Factor Depending on Weather\",\n       x = \"\", y = \"Proportion of All Bike Crashes\",\n       fill = \"Contributing Factor\") +\n  \n  theme_minimal() +\n  \n  theme(legend.position = \"right\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nbike_crashes3 &lt;- bike_crashes %&gt;% \n  mutate(is_rainy= if_else(PRCP &gt; 2, \"Rain\", \"Dry\"))\n\ntop_factors &lt;- bike_crashes3 %&gt;%\n  count(is_rainy, top_factor) %&gt;%\n  group_by(is_rainy) %&gt;%\n  slice_max(n, n = 10) %&gt;%\n  ungroup() %&gt;%\n  mutate(top_factor = fct_reorder(top_factor, n, sum))\n\n\n\nggplot(top_factors, aes(x = is_rainy, y = n, fill = top_factor)) +\n  \n  geom_col(position = \"fill\", color = \"white\", size = 0.3) +\n  \n  scale_y_continuous(labels = percent) +\n  \n  scale_fill_viridis_d(option = \"turbo\") + #took me forever to find a good color scheme lol\n  \n  labs(title = \"Contributing Factor Depending on Weather\",\n       x = \"\", y = \"Proportion of All Bike Crashes\",\n       fill = \"Contributing Factor\") +\n  \n  theme_minimal() +\n  \n  theme(legend.position = \"right\")\n\n\n\n\n\n\n\n\n\nWe see a few more factors come into play. Passing too closely has an effect and this is probably due to another variable that increase “View Obstructed” likely due to heavy rainfall. And of Course pavement slippery plays a role which is to be expected. It could also be noted that there is a decrease in the driver distraction factor which implies people pay more attention while its raining.",
    "crumbs": [
      "Story Telling",
      "Project 1"
    ]
  },
  {
    "objectID": "Story_Telling/project1.html#data-collection-and-filtering",
    "href": "Story_Telling/project1.html#data-collection-and-filtering",
    "title": "NYC Bikes",
    "section": "",
    "text": "In this analysis I use data collected from Kaggle. Namely, the Central Park NYC Weather Information data set that has weather information from the central park weather station from the years 2000-2022. As well as the Motor Vehicle Collisions - Crashes data set that has all police reported crashes in NYC. To keep the analysis relevant I decided to filter the data to include only years 2021 and 2022 (the two most recent years from the weather data set). I then filtered the motor vehicle collisions in two ways.\n\nBy longitude and latitude to focus on Manhattan surrounding central park, so the weather information might be accurate to the crash incidents.\nI limited the crashes to only those that included a bicycle since that is our target group.\n\n\n\nShow the code\nny1 &lt;- ny %&gt;%\n  mutate(`CRASH DATE` = mdy(`CRASH DATE`))\n\n\nny_clean &lt;- ny1 %&gt;%\n  filter(!is.na(LATITUDE), !is.na(LONGITUDE),\n         LATITUDE  &gt; 40.708073, LATITUDE  &lt; 40.833170,\n         LONGITUDE &gt; -74.013195, LONGITUDE &lt; -73.930574)\n\n\nny_2022 &lt;- ny_clean %&gt;%\n  filter(year(`CRASH DATE`) &gt;= 2021 & year(`CRASH DATE`) &lt;= 2022) %&gt;%\n  rename(DATE = `CRASH DATE`)\n\n\nwet_clean &lt;- wet %&gt;%\n  filter(year(DATE) &gt;= 2021 & year(DATE) &lt;= 2022,\n         STATION == \"USW00094728\") %&gt;%\n  select(DATE, PRCP, TMAX, TMIN, SNOW)\n\n# Final dataset with weather\nny8 &lt;- ny_2022 %&gt;%\n  left_join(wet_clean, by = \"DATE\")\n\n\nbike_crashes &lt;- ny8 %&gt;%\n  filter(`NUMBER OF CYCLIST INJURED` &gt; 0 | `NUMBER OF CYCLIST KILLED` &gt; 0 |\n         str_detect(tolower(`VEHICLE TYPE CODE 1`), \"bike|bicycle\") |\n         str_detect(tolower(`VEHICLE TYPE CODE 2`), \"bike|bicycle\") |\n         str_detect(tolower(`VEHICLE TYPE CODE 3`), \"bike|bicycle\") |\n         str_detect(tolower(`VEHICLE TYPE CODE 4`), \"bike|bicycle\") |\n         str_detect(tolower(`VEHICLE TYPE CODE 5`), \"bike|bicycle\")) %&gt;%\n  mutate(\n    year= year(DATE),\n    month = month(DATE, label = TRUE),\n    day_of_week = wday(DATE, label = TRUE, abbr = FALSE),\n    is_rainy= if_else(PRCP &gt; .05, \"Rain\", \"Dry\"),    # &gt;0.01 inches = rainy day\n    severity = case_when(\n      `NUMBER OF CYCLIST KILLED` &gt; 0 ~ \"Fatal\",\n      `NUMBER OF CYCLIST INJURED` &gt; 0 ~ \"Injury\",\n      TRUE ~ \"Property Damage Only\"\n    ),top_factor = `CONTRIBUTING FACTOR VEHICLE 1`,\n    top_factor = if_else(is.na(top_factor) | top_factor %in% c(\"\", \"Unspecified\"),\n                         \"Other/Unspecified\", top_factor))\n\n\n\ncat(\"Total bike-involved crashes 2021-2022:\", nrow(bike_crashes), \"\\n\")\n\n\nTotal bike-involved crashes 2021-2022: 4685",
    "crumbs": [
      "Story Telling",
      "Project 1"
    ]
  },
  {
    "objectID": "Story_Telling/project1.html#data-wrangling",
    "href": "Story_Telling/project1.html#data-wrangling",
    "title": "NYC Bikes",
    "section": "",
    "text": "The data wrangling process was made relatively simple by Kaggle’s high standard of clean data. Most of the adjustments were simple filters to target the data I needed, mutates to add categorical bins, as well as a join to combine the data sets. As you can see this left us with 4,685 rows of data to work with.\nThere were a few choices that I had to make while defining a “rainy” day or the “severity” of the accident. I choose classify any precipitation &gt; 0.05 mm/hr as a rainy day. (I will examine the effects of changing this number later in the analysis). Although this is in reality very little rain it is still enough to make the pavement wet and have an effect on the accident rates. In my second graph below I examine the precipitation vs bike crashes and find very little relevance and so this decision seems to be inconsequential. Severity was determined as follows, if there were any fatalities than the accident was considered “Fatal”, if there was an injury than it was grouped as “Injury” and if neither of these, the accident was classified as “Property Damage Only” under the assumption that some damage occurred to the bike or vehicle.",
    "crumbs": [
      "Story Telling",
      "Project 1"
    ]
  },
  {
    "objectID": "Story_Telling/project1.html#mapping-the-data",
    "href": "Story_Telling/project1.html#mapping-the-data",
    "title": "NYC Bikes",
    "section": "",
    "text": "The map below serves as the focal point of this project, and it servers a few function.\n\nIt shows the density of accidents such that it is easy to determine problematic areas.\nThe marker of each accident is color coded for the type or weather, or whether or not the accident was fatal. Since a Fatal accident is viewed with more gravity I decided this would trump the weather color coding, however by clicking on a marker you are able to see weather information for that day.\nThe interactive map shows the reason for each accident. This could be useful if you are examining a particular area and trying to determine if there is a correlation between that area and the contributing factor. (For example there might be more “distracted driver” factors around Times Square.)\n\nUser note: In order to find the most dense crash area simply click on the cluster with the largest number and continue to do so until you reach the street level were you can click on each marker to get more information.\n\n\nShow the code\npal &lt;- colorFactor(\n  palette = c(\"Dry\" = \"orange\", \"Rain\" = \"red\", \"Fatal\" = \"dodgerblue2\"),\n    domain = c(\"Dry\", \"Rain\", \"Fatal\")) # after like 20mins of playing with it I just accepted it's weird\n\nleaflet(data = bike_crashes) %&gt;%\n\n  addProviderTiles(providers$CartoDB.Positron) %&gt;%\n  \n    addHeatmap(\n    lng = ~LONGITUDE, lat = ~LATITUDE,\n    blur = 25, max = 0.1, radius = 15) %&gt;%\n  \n  addCircleMarkers(\n    lng = ~LONGITUDE, lat = ~LATITUDE,\n    radius = 10,\n    color = ~pal(ifelse(`NUMBER OF CYCLIST KILLED` &gt; 0, \"Fatal\", is_rainy)),\n    fillOpacity = 1,\n    \n    popup = ~paste(\n      \"&lt;b&gt;Date:&lt;/b&gt;\", DATE, \"&lt;br&gt;\",\n      \"&lt;b&gt;Weather:&lt;/b&gt;\", is_rainy, \"(\", round(PRCP,2), \" mm/hr)\", \"&lt;br&gt;\",\n      \"&lt;b&gt;Injured:&lt;/b&gt;\", `NUMBER OF CYCLIST INJURED`,\n      \"&lt;b&gt;Killed:&lt;/b&gt;\", `NUMBER OF CYCLIST KILLED`, \"&lt;br&gt;\",\n      \"&lt;b&gt;Main factor:&lt;/b&gt;\", top_factor),\n    \n    clusterOptions = markerClusterOptions() # Had some help making the popups and clusters\n  ) %&gt;%\n  addLegend(\"bottomright\",\n            pal = pal, values = c(\"Dry\", \"Rain\", \"Fatal\"),\n            title = \"Weather / Severity\")",
    "crumbs": [
      "Story Telling",
      "Project 1"
    ]
  },
  {
    "objectID": "Story_Telling/project1.html#the-rain-effect",
    "href": "Story_Telling/project1.html#the-rain-effect",
    "title": "NYC Bikes",
    "section": "",
    "text": "The graph below shows the correlation between rainfall (precipitation) and bike crashes. The purpose was to see if there was in fact a correlation between the amount of rain and the number of crashes. The answer seems to be no. My theory is that the more that it rains, the less cyclists there are on the road. To determine whether there is a higher proportion of crashes per rider one would have to know how many cyclists are riding at that moment and out of that total number how many got into an accident. Unfortunately I don’t think that data is feasible to collect. Using the slider you can see that often a peak in precipitation is met with a dip in crashes, meaning a weak correlation, while there some spikes that align the majority miss each other.\n\n\nShow the code\ndaily &lt;- bike_crashes %&gt;%\n  count(DATE, is_rainy) %&gt;%\n  complete(DATE = seq(min(DATE), max(DATE), by = \"day\"), fill = list(n = 0)) %&gt;%\n  left_join(select(wet_clean, DATE, PRCP), by = \"DATE\") %&gt;%\n  replace_na(list(PRCP = 0))\n\nts_data &lt;- xts(daily[, c(\"n\", \"PRCP\")], order.by = daily$DATE)\n\ndygraph(ts_data, main = \"Daily Bicycle Crashes vs Precipitation (2021-2022)\") %&gt;%\n  \n  dySeries(\"n\", label = \"Bike Crashes\", color = \"red\") %&gt;%\n  \n  dySeries(\"PRCP\", label = \"Precipitation (mm)\", axis = \"y2\", color = \"royalblue\") %&gt;%\n  \n  dyAxis(\"y\", label = \"Number of Crashes\") %&gt;%\n  \n  dyAxis(\"y2\", label = \"Precipitation (mm)\", independentTicks = TRUE) %&gt;%\n  \n  dyRangeSelector() %&gt;%\n  \n  dyHighlight(highlightSeriesOpts = list(strokeWidth = 3)) %&gt;%\n  \n  dyOptions(fillGraph = TRUE) \n\n\n\n\n\n\nI made a simplified graph to show the average number of bike crashes on each day of the week split between rainy and dry days. It appears the fewest number of people are traveling Sunday, which makes sense and there is a gradual increase throughout the week with a peak on Thursday and Friday. Notice that there are fewer crashes on rainy days each day of the week, except for Tuesday by a small margin once again confirming my theory of fewer bike commuters on those wet days.\n\n\nShow the code\ndaily_rates &lt;- bike_crashes %&gt;%\n  count(DATE, day_of_week, is_rainy) %&gt;%\n  group_by(day_of_week, is_rainy) %&gt;%\n  summarise(avg_crashes = mean(n)) %&gt;%\n  ungroup()\n\n\nggplot(daily_rates, aes(x = day_of_week, y = avg_crashes, fill = is_rainy)) +\n  \n\n  geom_col(position = \"dodge\", color = \"black\", size = 0.3) +\n  \n  scale_fill_manual(values = c(\"Dry\" = \"orange\", \"Rain\" = \"dodgerblue2\"), name = \"\") +\n  \n  labs(title = \"Bike Crashes, Rainy vs Dry Days\",\n       subtitle = \"Average daily crashes (2021-2022)\",\n       x = \"\",\n       y = \"Average Number of Bike Crashes per Day\") +\n  \n  theme_minimal() +\n  \n  theme(legend.position = \"top\")\n\n\n\n\n\n\n\n\n\nFor the sake of trying to uncover trends I’m going to change the standard for what is considered a rainy day by tripling the mm/hr precipitation rate from .05mm to 1.5mm/hr. The goal is to show the effect that more rain has on road conditions. If there is little to no change than we can conclude that rain plays little affect in the number of crashes. However if there is an effect we can assume that there is in fact a correlation\n\n\nShow the code\nbike_crashes2 &lt;- bike_crashes %&gt;% \n  mutate(is_rainy= if_else(PRCP &gt; 1.5, \"Rain\", \"Dry\"))\n\n\ndaily_rates2 &lt;- bike_crashes2 %&gt;%\n  count(DATE, day_of_week, is_rainy) %&gt;%\n  group_by(day_of_week, is_rainy) %&gt;%\n  summarise(avg_crashes = mean(n)) %&gt;%\n  ungroup()\n\nggplot(daily_rates2, aes(x = day_of_week, y = avg_crashes, fill = is_rainy)) +\n  \n\n  geom_col(position = \"dodge\", color = \"black\", size = 0.3) +\n  \n  scale_fill_manual(values = c(\"Dry\" = \"orange\", \"Rain\" = \"dodgerblue2\"), name = \"\") +\n  \n  labs(title = \"Bike Crashes, Rainy vs Dry Days\",\n       subtitle = \"Average daily crashes (2021-2022)\",\n       x = \"\",\n       y = \"Average Number of Bike Crashes per Day\") +\n  \n  theme_minimal() +\n  \n  theme(legend.position = \"top\")\n\n\n\n\n\n\n\n\n\nTaking a look at the graph we see that there was a change in the average number of accidents a day for most days it appears that Tuesday sees the greatest differential towards rainy day crashes and Saturday for dry day. Notably Saturday and Sunday have the biggest difference in favor of dry days most likely do the elastic need to travel those days.",
    "crumbs": [
      "Story Telling",
      "Project 1"
    ]
  },
  {
    "objectID": "Story_Telling/project1.html#examining-causes-for-accidents.",
    "href": "Story_Telling/project1.html#examining-causes-for-accidents.",
    "title": "NYC Bikes",
    "section": "",
    "text": "Finally the last chart examines the cause of accident depending on the weather that day. The two bars are almost identical such that little can be said for the affect of the rain on the reason for the accident. Once again lets change the classification for rainy day and see the effect.\n\n\nShow the code\ntop_factors &lt;- bike_crashes %&gt;%\n  count(is_rainy, top_factor) %&gt;%\n  group_by(is_rainy) %&gt;%\n  slice_max(n, n = 10) %&gt;%\n  ungroup() %&gt;%\n  mutate(top_factor = fct_reorder(top_factor, n, sum))\n\n\n\nggplot(top_factors, aes(x = is_rainy, y = n, fill = top_factor)) +\n  \n  geom_col(position = \"fill\", color = \"white\", size = 0.3) +\n  \n  scale_y_continuous(labels = percent) +\n  \n  scale_fill_viridis_d(option = \"turbo\") + #took me forever to find a good color scheme lol\n  \n  labs(title = \"Contributing Factor Depending on Weather\",\n       x = \"\", y = \"Proportion of All Bike Crashes\",\n       fill = \"Contributing Factor\") +\n  \n  theme_minimal() +\n  \n  theme(legend.position = \"right\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nbike_crashes3 &lt;- bike_crashes %&gt;% \n  mutate(is_rainy= if_else(PRCP &gt; 2, \"Rain\", \"Dry\"))\n\ntop_factors &lt;- bike_crashes3 %&gt;%\n  count(is_rainy, top_factor) %&gt;%\n  group_by(is_rainy) %&gt;%\n  slice_max(n, n = 10) %&gt;%\n  ungroup() %&gt;%\n  mutate(top_factor = fct_reorder(top_factor, n, sum))\n\n\n\nggplot(top_factors, aes(x = is_rainy, y = n, fill = top_factor)) +\n  \n  geom_col(position = \"fill\", color = \"white\", size = 0.3) +\n  \n  scale_y_continuous(labels = percent) +\n  \n  scale_fill_viridis_d(option = \"turbo\") + #took me forever to find a good color scheme lol\n  \n  labs(title = \"Contributing Factor Depending on Weather\",\n       x = \"\", y = \"Proportion of All Bike Crashes\",\n       fill = \"Contributing Factor\") +\n  \n  theme_minimal() +\n  \n  theme(legend.position = \"right\")\n\n\n\n\n\n\n\n\n\nWe see a few more factors come into play. Passing too closely has an effect and this is probably due to another variable that increase “View Obstructed” likely due to heavy rainfall. And of Course pavement slippery plays a role which is to be expected. It could also be noted that there is a decrease in the driver distraction factor which implies people pay more attention while its raining.",
    "crumbs": [
      "Story Telling",
      "Project 1"
    ]
  },
  {
    "objectID": "Story_Telling/project1.html#limitations-and-future-work",
    "href": "Story_Telling/project1.html#limitations-and-future-work",
    "title": "NYC Bikes",
    "section": "Limitations and Future Work",
    "text": "Limitations and Future Work\nTo understand the effect weather has on crashed more data could be collected. It might be advantageous to combine multiple weather stations and examine the effects across a greater area. Another option would be to zoom in and focus on an area in closer proximity to the weather station to ensure that the rain is really effecting the riders as it is thought to be. Greater accuracy could also be achieved through having time stamps of the accidents and time stamps of the rain to line, rather than just a 24 period that I used with in this analysis.",
    "crumbs": [
      "Story Telling",
      "Project 1"
    ]
  },
  {
    "objectID": "Cleansing_Projects/project3.html",
    "href": "Cleansing_Projects/project3.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Data Cleansing",
      "Project 3"
    ]
  },
  {
    "objectID": "Cleansing_Projects/project4.html",
    "href": "Cleansing_Projects/project4.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Data Cleansing",
      "Project 4"
    ]
  },
  {
    "objectID": "Cleansing_Projects/project5.html",
    "href": "Cleansing_Projects/project5.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Data Cleansing",
      "Project 5"
    ]
  },
  {
    "objectID": "full_stack.html",
    "href": "full_stack.html",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics",
    "crumbs": [
      "Full Stack"
    ]
  },
  {
    "objectID": "full_stack.html#title-2-header",
    "href": "full_stack.html#title-2-header",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics",
    "crumbs": [
      "Full Stack"
    ]
  },
  {
    "objectID": "Cleansing_Exploration/project2.html",
    "href": "Cleansing_Exploration/project2.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top"
  },
  {
    "objectID": "Cleansing_Exploration/project1.html",
    "href": "Cleansing_Exploration/project1.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top"
  },
  {
    "objectID": "notebooks/Exploration_02.html",
    "href": "notebooks/Exploration_02.html",
    "title": "Data Exploration 02",
    "section": "",
    "text": "You’re working as a data analyst at a cereal marketing company in New York.\nIn a strategy meeting, the marketing director tells you that in 2018, the US weight loss industry was worth over $72 Billion dollars, growing 4% compared to the previous year.\nIn contrast, sales of cold cereal fell 6% to $8.5 billion during the same time period.\nCereal executives have approached the marketing company asking how they can somehow tap into the weight loss market growth to boost the sales of their cereal brands.\nYour assignment is to analyze a dataset of nutritional information for major US cereals, and calculate some metrics that can be used by the marketing team."
  },
  {
    "objectID": "notebooks/Exploration_02.html#part-1-import-pandas-and-load-the-data",
    "href": "notebooks/Exploration_02.html#part-1-import-pandas-and-load-the-data",
    "title": "Data Exploration 02",
    "section": "Part 1: Import Pandas and load the data",
    "text": "Part 1: Import Pandas and load the data\nRemember to import Pandas the conventional way. If you’ve forgotten how, you may want to review Data Exploration 01.\nThe dataset for this exploration is stored at the following url:\nhttps://raw.githubusercontent.com/byui-cse/cse450-course/master/data/cereal.csv\nThere are lots of ways to load data into your workspace. The easiest way in this case is to ask Pandas to do it for you.\n\nInitial Data Analysis\nOnce you’ve loaded the data, it’s a good idea to poke around a little bit to find out what you’re dealing with.\nSome questions you might ask include:\n\nWhat does the data look like?\nWhat kind of data is in each column?\nDo any of the columns have missing values?\n\n\n# Part 1: Enter your code below to import Pandas according to the\n# conventional method. Then load the dataset into a Pandas dataframe.\n\nimport pandas as pd\n\nurl = 'https://raw.githubusercontent.com/byui-cse/cse450-course/master/data/cereal.csv'\n\ndf = pd.read_csv(url)\n\nprint(df.head)\nprint(df.info)\ndf.isnull().sum()\n# Write any code needed to explore the data by seeing what the first few\n# rows look like. Then display a technical summary of the data to determine\n# the data types of each column, and which columns have missing data.\n\n&lt;bound method NDFrame.head of                          name mfr type  calories  protein  fat  sodium  fiber  \\\n0                   100% Bran   N    C        70        4    1     130   10.0   \n1           100% Natural Bran   Q    C       120        3    5      15    2.0   \n2                    All-Bran   K    C        70        4    1     260    9.0   \n3   All-Bran with Extra Fiber   K    C        50        4    0     140   14.0   \n4              Almond Delight   R    C       110        2    2     200    1.0   \n..                        ...  ..  ...       ...      ...  ...     ...    ...   \n72                    Triples   G    C       110        2    1     250    0.0   \n73                       Trix   G    C       110        1    1     140    0.0   \n74                 Wheat Chex   R    C       100        3    1     230    3.0   \n75                   Wheaties   G    C       100        3    1     200    3.0   \n76        Wheaties Honey Gold   G    C       110        2    1     200    1.0   \n\n    carbo  sugars  potass  vitamins  shelf  weight  cups     rating  \n0     5.0       6     280        25      3     1.0  0.33  68.402973  \n1     8.0       8     135         0      3     1.0  1.00  33.983679  \n2     7.0       5     320        25      3     1.0  0.33  59.425505  \n3     8.0       0     330        25      3     1.0  0.50  93.704912  \n4    14.0       8      -1        25      3     1.0  0.75  34.384843  \n..    ...     ...     ...       ...    ...     ...   ...        ...  \n72   21.0       3      60        25      3     1.0  0.75  39.106174  \n73   13.0      12      25        25      2     1.0  1.00  27.753301  \n74   17.0       3     115        25      1     1.0  0.67  49.787445  \n75   17.0       3     110        25      1     1.0  1.00  51.592193  \n76   16.0       8      60        25      1     1.0  0.75  36.187559  \n\n[77 rows x 16 columns]&gt;\n&lt;bound method DataFrame.info of                          name mfr type  calories  protein  fat  sodium  fiber  \\\n0                   100% Bran   N    C        70        4    1     130   10.0   \n1           100% Natural Bran   Q    C       120        3    5      15    2.0   \n2                    All-Bran   K    C        70        4    1     260    9.0   \n3   All-Bran with Extra Fiber   K    C        50        4    0     140   14.0   \n4              Almond Delight   R    C       110        2    2     200    1.0   \n..                        ...  ..  ...       ...      ...  ...     ...    ...   \n72                    Triples   G    C       110        2    1     250    0.0   \n73                       Trix   G    C       110        1    1     140    0.0   \n74                 Wheat Chex   R    C       100        3    1     230    3.0   \n75                   Wheaties   G    C       100        3    1     200    3.0   \n76        Wheaties Honey Gold   G    C       110        2    1     200    1.0   \n\n    carbo  sugars  potass  vitamins  shelf  weight  cups     rating  \n0     5.0       6     280        25      3     1.0  0.33  68.402973  \n1     8.0       8     135         0      3     1.0  1.00  33.983679  \n2     7.0       5     320        25      3     1.0  0.33  59.425505  \n3     8.0       0     330        25      3     1.0  0.50  93.704912  \n4    14.0       8      -1        25      3     1.0  0.75  34.384843  \n..    ...     ...     ...       ...    ...     ...   ...        ...  \n72   21.0       3      60        25      3     1.0  0.75  39.106174  \n73   13.0      12      25        25      2     1.0  1.00  27.753301  \n74   17.0       3     115        25      1     1.0  0.67  49.787445  \n75   17.0       3     110        25      1     1.0  1.00  51.592193  \n76   16.0       8      60        25      1     1.0  0.75  36.187559  \n\n[77 rows x 16 columns]&gt;\n\n\n\n\n\n\n\n\n\n0\n\n\n\n\nname\n0\n\n\nmfr\n0\n\n\ntype\n0\n\n\ncalories\n0\n\n\nprotein\n0\n\n\nfat\n0\n\n\nsodium\n0\n\n\nfiber\n0\n\n\ncarbo\n0\n\n\nsugars\n0\n\n\npotass\n0\n\n\nvitamins\n0\n\n\nshelf\n0\n\n\nweight\n0\n\n\ncups\n0\n\n\nrating\n0\n\n\n\n\ndtype: int64"
  },
  {
    "objectID": "notebooks/Exploration_02.html#part-2-calculate-summary-statistics",
    "href": "notebooks/Exploration_02.html#part-2-calculate-summary-statistics",
    "title": "Data Exploration 02",
    "section": "Part 2: Calculate Summary Statistics",
    "text": "Part 2: Calculate Summary Statistics\nThe marketing team has determined that when choosing a cereal, consumers are most interested in calories, sugars, fiber, fat, and protein.\nFirst, let’s calcuate some summary statistics for these categories across the entire dataset. We’re particularly intrested in the mean, median, standard deviation, min, and max values.\nThere are multiple ways to accomplish this.\n\n# Part 2: Enter your code below to calculate summary statistics for the\n# calories, sugars, fiber, fat, and protein features.\n\ndf[['calories', 'protein', 'fat', 'sugars', 'fiber']].describe()\n\n\n    \n\n\n\n\n\n\ncalories\nprotein\nfat\nsugars\nfiber\n\n\n\n\ncount\n77.000000\n77.000000\n77.000000\n77.000000\n77.000000\n\n\nmean\n106.883117\n2.545455\n1.012987\n6.922078\n2.151948\n\n\nstd\n19.484119\n1.094790\n1.006473\n4.444885\n2.383364\n\n\nmin\n50.000000\n1.000000\n0.000000\n-1.000000\n0.000000\n\n\n25%\n100.000000\n2.000000\n0.000000\n3.000000\n1.000000\n\n\n50%\n110.000000\n3.000000\n1.000000\n7.000000\n2.000000\n\n\n75%\n110.000000\n3.000000\n2.000000\n11.000000\n3.000000\n\n\nmax\n160.000000\n6.000000\n5.000000\n15.000000\n14.000000"
  },
  {
    "objectID": "notebooks/Exploration_02.html#part-3-transform-data",
    "href": "notebooks/Exploration_02.html#part-3-transform-data",
    "title": "Data Exploration 02",
    "section": "Part 3: Transform Data",
    "text": "Part 3: Transform Data\nTo make analysis easier, you want to convert the manufacturer codes used in the dataset to the manufacturer names.\nFirst, display the count of each manufacturer code value used in the dataset (found in the mfr column).\nThen, create a new column with the appropriate manufacturer name for each entry, using this mapping:\nA = American Home Food Products\nG = General Mills\nK = Kelloggs\nN = Nabisco\nP = Post\nQ = Quaker Oats\nR = Ralston Purina\n\nNote: While the tutorial linked above uses the replace function, using the map function instead can often be much faster and more memory efficient, especially for large datasets.\n\n\n# Display the count of values for the manufacturer code (\"mfr\" column), then\n# create a new column containing the appropriate manufacturer names.\nmfr_map = {\n    'A': 'American Home Food Products',\n    'G': 'General Mills',\n    'K': 'Kelloggs',\n    'N': 'Nabisco',\n    'P': 'Post',\n    'Q': 'Quaker Oats',\n    'R': 'Ralston Purina'\n}\n\n\ndf['mfr_name'] = df['mfr'].map(mfr_map)\n\n\ndf.head()\n\n\n\n\n\n    \n\n\n\n\n\n\nname\nmfr\ntype\ncalories\nprotein\nfat\nsodium\nfiber\ncarbo\nsugars\npotass\nvitamins\nshelf\nweight\ncups\nrating\nmfr_name\n\n\n\n\n0\n100% Bran\nN\nC\n70\n4\n1\n130\n10.0\n5.0\n6\n280\n25\n3\n1.0\n0.33\n68.402973\nNabisco\n\n\n1\n100% Natural Bran\nQ\nC\n120\n3\n5\n15\n2.0\n8.0\n8\n135\n0\n3\n1.0\n1.00\n33.983679\nQuaker Oats\n\n\n2\nAll-Bran\nK\nC\n70\n4\n1\n260\n9.0\n7.0\n5\n320\n25\n3\n1.0\n0.33\n59.425505\nKelloggs\n\n\n3\nAll-Bran with Extra Fiber\nK\nC\n50\n4\n0\n140\n14.0\n8.0\n0\n330\n25\n3\n1.0\n0.50\n93.704912\nKelloggs\n\n\n4\nAlmond Delight\nR\nC\n110\n2\n2\n200\n1.0\n14.0\n8\n-1\n25\n3\n1.0\n0.75\n34.384843\nRalston Purina"
  },
  {
    "objectID": "notebooks/Exploration_02.html#part-4-visualization",
    "href": "notebooks/Exploration_02.html#part-4-visualization",
    "title": "Data Exploration 02",
    "section": "Part 4: Visualization",
    "text": "Part 4: Visualization\nLet’s do some more data exploration visually.\nImport your visualization library of choice and set any needed configuration options.\n\n# Import your visualization library\nimport plotly.express as px\n\n\n\nSugar Distribution\nMarketing tells us that their surveys have revealed that sugar content is the number one concern of consumers when choosing cereal.\nThey would like to see the following visualizations:\n\nA histogram plot of the sugar content in all cereals.\nA scatter plot showing the relationship between sugar and calories.\nA box plot showing the distribution of sugar content by manufacturer.\n\n\n# Create the three visualzations requested by the the marketing team\n\n# 1. Histogram of Sugar Content\nfig_hist = px.histogram(df, x=\"sugars\",\n                         title=\"Distribution of Sugar Content in Cereals\",\n                         labels={'sugars': 'Sugar (grams)'},\n                         nbins=20,\n                         color_discrete_sequence=['indianred'])\nfig_hist.show()\n\n\n\n\n\n                                \n                                            \n\n\n\n\n\nfig_scatter = px.scatter(df, x=\"sugars\", y=\"calories\",\n                         title=\"Relationship Between Sugar and Calories\",\n                         labels={'sugars': 'Sugar (grams)', 'calories': 'Calories'},\n                         hover_name='name', # Shows cereal name on hover\n                         trendline=\"ols\")   # Adds a line of best fit\nfig_scatter.show()\n\n\n\n\n                                \n                                            \n\n\n\n\n\nfig_box = px.box(df, x=\"mfr_name\", y=\"sugars\",\n                 title=\"Sugar Content Distribution by Manufacturer\",\n                 labels={'mfr_name': 'Manufacturer', 'sugars': 'Sugar (grams)'},\n                 color=\"mfr_name\")\nfig_box.update_layout(xaxis={'categoryorder':'total descending'})\nfig_box.show()"
  },
  {
    "objectID": "notebooks/Exploration_02.html#above-and-beyond",
    "href": "notebooks/Exploration_02.html#above-and-beyond",
    "title": "Data Exploration 02",
    "section": "🌟 Above and Beyond 🌟",
    "text": "🌟 Above and Beyond 🌟\nThe marketing team is pleased with what you’ve accomplished so far. They have a meeting with top cereal executives in the morning, and they’d like you to do as many of the following additional tasks as you have time for:\n\nWeight Watchers used to have an older points system that used this formula: (calories / 50) + (fat / 12) - (fiber / 5), but only the first 4 grams of fiber were included in the calculation. For comparison’s sake, create an additional column with the calculation for the old points system.\nMarketing really likes the boxplot of the sugar content for each cereal, they’d like similar plots for calories and fat, but using different color schemes for each chart."
  },
  {
    "objectID": "Full_Stack/project2.html",
    "href": "Full_Stack/project2.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Full Stack",
      "Project 2"
    ]
  },
  {
    "objectID": "Full_Stack/project1.html",
    "href": "Full_Stack/project1.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Full Stack",
      "Project 1"
    ]
  }
]